# -*- coding: utf-8 -*-
"""
Tests for training assessment type.
"""
import copy
from django.db import DatabaseError
import ddt
from mock import patch
from openassessment.test_utils import CacheResetTest
from submissions import api as sub_api
from openassessment.assessment.api import student_training as training_api
from openassessment.assessment.errors import StudentTrainingRequestError, StudentTrainingInternalError
from openassessment.assessment.models import StudentTrainingWorkflow


@ddt.ddt
class StudentTrainingAssessmentTest(CacheResetTest):
    """
    Tests for the training assessment type.
    """
    longMessage = True

    STUDENT_ITEM = {
        'student_id': u'ğ“½ğ“®ğ“¼ğ“½ ğ“¼ğ“½ğ“¾ğ“­ğ“®ğ“·ğ“½',
        'item_id': u'ğ–™ğ–Šğ–˜ğ–™ ğ–ğ–™ğ–Šğ–’',
        'course_id': u'Õ‡Ñ”à¸£Õ‡ Ï‚à¹à¸¢Ğ³à¸£Ñ”',
        'item_type': u'openassessment'
    }

    ANSWER = u'áº—Ã«á¹¡áº— Ã¤á¹…á¹¡áº…Ã«á¹›'

    RUBRIC_OPTIONS = [
        {
            "order_num": 0,
            "name": u"ğ’‘ğ’ğ’ğ’“",
            "explanation": u"ğ•»ğ–”ğ–”ğ–— ğ–ğ–”ğ–‡!",
            "points": 0,
        },
        {
            "order_num": 1,
            "name": u"ğ“°ğ“¸ğ“¸ğ“­",
            "explanation": u"ï»­Ñ»Ñ»É— ï»Ñ»à¹’!",
            "points": 1,
        },
        {
            "order_num": 2,
            "name": "Ñ”Ï‡Â¢Ñ”â„“â„“Ñ”Î·Ñ‚",
            "explanation": "ä¹‡ï¾’cä¹‡ï¾šï¾šä¹‡åˆ€ï½² ï¾Œoä¹ƒ!",
            "points": 2,
        },
    ]

    RUBRIC = {
        'prompt': u"ĞœĞ¾ÑŠĞ-â†Ñ–ÑĞº; Ğ¾Ñ“, Ğ“Ğ‚Ñ Ğ©Ğ‚Ğ°lÑ",
        'criteria': [
            {
                "order_num": 0,
                "name": u"vÃ¸È¼ÈºÆ€áµ¾Å‚ÈºÉÉ",
                "prompt": u"Ä¦Ã¸w vÈºÉÉ¨É‡Ä‘ É¨s Å§Ä§É‡ vÃ¸È¼ÈºÆ€áµ¾Å‚ÈºÉÉ?",
                "options": RUBRIC_OPTIONS
            },
            {
                "order_num": 1,
                "name": u"ï»­É¼à¸„à¹“à¹“à¸„É¼",
                "prompt": u"ğ•³ğ–”ğ–œ ğ–ˆğ–”ğ–—ğ–—ğ–Šğ–ˆğ–™ ğ–ğ–˜ ğ–™ğ–ğ–Š ğ–Œğ–—ğ–†ğ–’ğ–’ğ–†ğ–—?",
                "options": RUBRIC_OPTIONS
            }
        ]
    }

    EXAMPLES = [
        {
            'answer': (
                u"ğ•¿ğ–ğ–Šğ–—ğ–Š ğ–†ğ–—ğ–Š ğ–ˆğ–Šğ–—ğ–™ğ–†ğ–ğ–“ ğ––ğ–šğ–Šğ–Šğ–— ğ–™ğ–ğ–’ğ–Šğ–˜ ğ–†ğ–“ğ–‰ ğ–”ğ–ˆğ–ˆğ–†ğ–˜ğ–ğ–”ğ–“ğ–˜ ğ–ğ–“ ğ–™ğ–ğ–ğ–˜ ğ–˜ğ–™ğ–—ğ–†ğ–“ğ–Œğ–Š ğ–’ğ–ğ–ğ–Šğ–‰ ğ–†ğ–‹ğ–‹ğ–†ğ–ğ–— ğ–œğ–Š ğ–ˆğ–†ğ–‘ğ–‘ ğ–‘ğ–ğ–‹ğ–Š"
                u" ğ–œğ–ğ–Šğ–“ ğ–† ğ–’ğ–†ğ–“ ğ–™ğ–†ğ–ğ–Šğ–˜ ğ–™ğ–ğ–ğ–˜ ğ–œğ–ğ–”ğ–‘ğ–Š ğ–šğ–“ğ–ğ–›ğ–Šğ–—ğ–˜ğ–Š ğ–‹ğ–”ğ–— ğ–† ğ–›ğ–†ğ–˜ğ–™ ğ–•ğ–—ğ–†ğ–ˆğ–™ğ–ğ–ˆğ–†ğ–‘ ğ–ğ–”ğ–ğ–Š, ğ–™ğ–ğ–”ğ–šğ–Œğ– ğ–™ğ–ğ–Š ğ–œğ–ğ–™ ğ–™ğ–ğ–Šğ–—ğ–Šğ–”ğ–‹"
                u" ğ–ğ–Š ğ–‡ğ–šğ–™ ğ–‰ğ–ğ–’ğ–‘ğ– ğ–‰ğ–ğ–˜ğ–ˆğ–Šğ–—ğ–“ğ–˜, ğ–†ğ–“ğ–‰ ğ–’ğ–”ğ–—ğ–Š ğ–™ğ–ğ–†ğ–“ ğ–˜ğ–šğ–˜ğ–•ğ–Šğ–ˆğ–™ğ–˜ ğ–™ğ–ğ–†ğ–™ ğ–™ğ–ğ–Š ğ–ğ–”ğ–ğ–Š ğ–ğ–˜ ğ–†ğ–™ ğ–“ğ–”ğ–‡ğ–”ğ–‰ğ–'ğ–˜ ğ–Šğ–ğ–•ğ–Šğ–“ğ–˜ğ–Š ğ–‡ğ–šğ–™ ğ–ğ–ğ–˜ ğ–”ğ–œğ–“."
            ),
            'options_selected': {
                u"vÃ¸È¼ÈºÆ€áµ¾Å‚ÈºÉÉ": u"ğ“°ğ“¸ğ“¸ğ“­",
                u"ï»­É¼à¸„à¹“à¹“à¸„É¼": u"ğ’‘ğ’ğ’ğ’“",
            }
        },
        {
            'answer': u"TÅ‘á¹•-hÃ©Ã¡vÓ³ áºƒÃ¡Å› thÃ© Å›hÃ­á¹• Ã¡Å› Ã¡ dÃ­Å„Å„Ã©Å•ÄºÃ©Å›Å› Å›tÃºdÃ©Å„t áºƒÃ­th Ã¡ÄºÄº ÃÅ•Ã­Å›tÅ‘tÄºÃ© Ã­Å„ hÃ­Å› hÃ©Ã¡d.",
            'options_selected': {
                u"vÃ¸È¼ÈºÆ€áµ¾Å‚ÈºÉÉ": u"ğ’‘ğ’ğ’ğ’“",
                u"ï»­É¼à¸„à¹“à¹“à¸„É¼": u"Ñ”Ï‡Â¢Ñ”â„“â„“Ñ”Î·Ñ‚",
            }
        },
    ]

    def setUp(self):
        """
        Create a submission.
        """
        submission = sub_api.create_submission(self.STUDENT_ITEM, self.ANSWER)
        self.submission_uuid = submission['uuid']

    def test_training_workflow(self):

        # Start a workflow
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)

        # Initially, we should be on the first step
        self._assert_workflow_status(self.submission_uuid, 0, 2)

        # Get a training example
        self._assert_get_example(self.submission_uuid, 0, self.EXAMPLES, self.RUBRIC)

        # Assess the training example the same way the instructor did
        corrections = training_api.assess_training_example(
            self.submission_uuid,
            self.EXAMPLES[0]['options_selected']
        )
        self.assertEqual(corrections, dict())
        self._assert_workflow_status(self.submission_uuid, 1, 2)

        # Get another training example to assess
        self._assert_get_example(self.submission_uuid, 1, self.EXAMPLES, self.RUBRIC)

        # Give the example different scores than the instructor gave
        incorrect_assessment = {
            u"vÃ¸È¼ÈºÆ€áµ¾Å‚ÈºÉÉ": u"ğ“°ğ“¸ğ“¸ğ“­",
            u"ï»­É¼à¸„à¹“à¹“à¸„É¼": u"ğ“°ğ“¸ğ“¸ğ“­",
        }
        corrections = training_api.assess_training_example(
            self.submission_uuid, incorrect_assessment
        )

        # Expect that we get corrected and stay on the current example
        self.assertItemsEqual(corrections, self.EXAMPLES[1]['options_selected'])
        self._assert_workflow_status(self.submission_uuid, 1, 2)

        # Try again, and this time assess the same way as the instructor
        corrections = training_api.assess_training_example(
            self.submission_uuid, self.EXAMPLES[1]['options_selected']
        )
        self.assertEqual(corrections, dict())

        # Now we should have completed both assessments
        self._assert_workflow_status(self.submission_uuid, 2, 2)

    def test_assess_without_update(self):

        # Start a workflow
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)

        # Assess the first training example the same way the instructor did
        # but do NOT update the workflow
        corrections = training_api.assess_training_example(
            self.submission_uuid,
            self.EXAMPLES[0]['options_selected'],
            update_workflow=False
        )

        # Expect that we're still on the first step
        self.assertEqual(corrections, dict())
        self._assert_workflow_status(self.submission_uuid, 0, 2)

    @ddt.file_data('data/validate_training_examples.json')
    def test_validate_training_examples(self, data):
        errors = training_api.validate_training_examples(
            data['rubric'], data['examples']
        )
        msg = u"Expected errors {} but got {}".format(data['errors'], errors)
        self.assertItemsEqual(errors, data['errors'], msg=msg)

    def test_is_finished_no_workflow(self):
        # Without creating a workflow, we should not be finished
        self.assertFalse(training_api.submitter_is_finished(self.submission_uuid, dict()))

        # But since we're not being assessed by others, the "assessment" should be finished.
        self.assertTrue(training_api.assessment_is_finished(self.submission_uuid, dict()))

    def test_get_training_example_none_available(self):
        # Start a workflow and assess all training examples
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)
        self._assert_workflow_status(self.submission_uuid, 0, 2)

        for example in self.EXAMPLES:
            training_api.assess_training_example(self.submission_uuid, example['options_selected'])

        # Now we should be complete
        self._assert_workflow_status(self.submission_uuid, 2, 2)

        # ... and if we try to get another example, we should get None
        self.assertIs(
            training_api.get_training_example(self.submission_uuid), None
        )

    def test_get_training_example_no_workflow(self):
        # With no workflow defined, we should get an error
        with self.assertRaises(StudentTrainingRequestError):
            training_api.get_training_example(self.submission_uuid)

    def test_create_training_workflow_already_started(self):
        # Create a workflow for training
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)

        # Try to create a second workflow for the same submission,
        # expecting an error.
        with self.assertRaises(StudentTrainingRequestError):
            training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)

    def test_create_training_workflow_no_examples(self):
        # Try to create a training workflow with no examples
        # and expect an error.
        with self.assertRaises(StudentTrainingRequestError):
            training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, [])

    def test_create_training_workflow_no_submission(self):
        # Try to create a training workflow with an invalid submission UUID
        with self.assertRaises(StudentTrainingRequestError):
            training_api.create_training_workflow("not a submission!", self.RUBRIC, self.EXAMPLES)

    def test_assess_training_example_completed_workflow(self):
        # Start a workflow and assess all training examples
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)
        self._assert_workflow_status(self.submission_uuid, 0, 2)

        for example in self.EXAMPLES:
            training_api.assess_training_example(self.submission_uuid, example['options_selected'])

        # Try to assess again, and expect an error
        with self.assertRaises(StudentTrainingRequestError):
            training_api.assess_training_example(
                self.submission_uuid, self.EXAMPLES[0]['options_selected']
            )

    def test_assess_training_example_no_workflow(self):
        # With no workflow defined, we should get an error
        with self.assertRaises(StudentTrainingRequestError):
            training_api.assess_training_example(
                self.submission_uuid, self.EXAMPLES[0]['options_selected']
            )

    def test_get_workflow_status_no_workflow(self):
        # With no workflow defined, we should get an error
        # when we try to request the status.
        with self.assertRaises(StudentTrainingRequestError):
            training_api.get_workflow_status(self.submission_uuid)

    def test_create_workflow_invalid_rubric(self):
        # Rubric is missing a very important key!
        invalid_rubric = copy.deepcopy(self.RUBRIC)
        del invalid_rubric['criteria']

        with self.assertRaises(StudentTrainingRequestError):
            training_api.create_training_workflow(self.submission_uuid, invalid_rubric, self.EXAMPLES)

    def test_create_workflow_invalid_examples(self):
        # Training example is not a dictionary!
        with self.assertRaises(StudentTrainingRequestError):
            training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, ["not a dict!"])

    @patch.object(StudentTrainingWorkflow, 'create_workflow')
    def test_create_workflow_database_error(self, mock_db):
        mock_db.side_effect = DatabaseError("Kaboom!")
        with self.assertRaises(StudentTrainingInternalError):
            training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)

    @patch.object(StudentTrainingWorkflow.objects, 'get')
    def test_get_workflow_status_database_error(self, mock_db):
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)
        mock_db.side_effect = DatabaseError("Kaboom!")
        with self.assertRaises(StudentTrainingInternalError):
            training_api.get_workflow_status(self.submission_uuid)

    @patch.object(StudentTrainingWorkflow.objects, 'get')
    def test_get_training_example_database_error(self, mock_db):
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)
        mock_db.side_effect = DatabaseError("Kaboom!")
        with self.assertRaises(StudentTrainingInternalError):
            training_api.get_training_example(self.submission_uuid)

    @patch.object(StudentTrainingWorkflow.objects, 'get')
    def test_assess_training_example_database_error(self, mock_db):
        training_api.create_training_workflow(self.submission_uuid, self.RUBRIC, self.EXAMPLES)
        mock_db.side_effect = DatabaseError("Kaboom!")
        with self.assertRaises(StudentTrainingInternalError):
            training_api.assess_training_example(self.submission_uuid, self.EXAMPLES[0]['options_selected'])

    def _assert_workflow_status(self, submission_uuid, num_completed, num_total):
        """
        Check that the training workflow is on the expected step.

        Args:
            submission_uuid (str): Submission UUID of the student being trained.
            num_completed (int): The expected number of examples assessed correctly.
            num_total (int): The expected number of available examples.

        Returns:
            None

        Raises:
            AssertionError

        """
        # Check the workflow status (what step are we on?)
        status = training_api.get_workflow_status(submission_uuid)
        self.assertEqual(status['num_completed'], num_completed)
        self.assertEqual(status['num_total'], num_total)

        # Check whether the assessment step is completed
        # (used by the workflow API)
        is_finished = bool(num_completed == num_total)
        self.assertEqual(
            training_api.submitter_is_finished(submission_uuid, dict()),
            is_finished
        )

        # Assessment is finished should always be true,
        # since we're not being assessed by others.
        self.assertTrue(
            training_api.assessment_is_finished(submission_uuid, dict()),
        )

        # At no point should we receive a score!
        self.assertIs(training_api.get_score(submission_uuid, dict()), None)

    def _expected_example(self, input_example, rubric):
        """
        Return the training example we would expect to retrieve for an example.
        The retrieved example will include the rubric.

        Args:
            input_example (dict): The example dict we passed to the API.
            rubric (dict): The rubric for the example.

        Returns:
            dict

        """
        output_dict = copy.deepcopy(input_example)
        output_dict['rubric'] = rubric
        return output_dict

    def _assert_get_example(self, submission_uuid, order_num, input_examples, input_rubric):
        """
        Check the training example we get from the API.

        Args:
            submission_uuid (str): The submission UUID associated with the student being trained.
            order_num (int): The order number of the example we expect to retrieve.
            input_examples (list of dict): The examples we used to configure the training workflow.
            input_rubric (dict): The rubric we used to configure the training workflow.

        Returns:
            None

        Raises:
            AssertionError

        """
        example = training_api.get_training_example(submission_uuid)
        expected_example = self._expected_example(input_examples[order_num], input_rubric)
        self.assertItemsEqual(example, expected_example)
